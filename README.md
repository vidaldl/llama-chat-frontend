# Overview
This project is a React app that works as a front-end to my other project [llama-chat](https://github.com/vidaldl/llama-chat).
\
I wanted to have a lightweight front-end to the back-end project llama-chat is. This project will allow you to have separate chats with your local instance of Llama3.


[Check out my demo video!](https://youtu.be/-xMTIaUAF5I)

# Development Environment

I used VS Code as a code editor, Ollama running Llama3, and Node in this project. I also used PostMan to test my calls to the local Ollama server.

# Useful Websites

* [W3Schools - React](https://www.w3schools.com/react/)
* [React Learn](https://react.dev/learn/describing-the-ui)



## Requirements

- NodeJS
- React


## Installation

1. **Clone the repository:**
   ```bash
   git clone git@github.com:vidaldl/llama-chat-frontend.git
   cd llama-chat-frontend
   ```

2. **Install the required libraries:**
   ```bash
   npm install
   ```

3. **Make sure llama-chat is running**
For this front-end project to work properly you will need to run my other project [llama-chat](https://github.com/vidaldl/llama-chat).


## Usage
1. **Interact with Llama3:** \
    Run the Node server and access [localhost:3001](http://localhost:3001/) to start a conversation with Llama3:
    ```bash
   npm start
   ```

